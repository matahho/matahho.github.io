---
title: "ğŸ’¾ Data Engineer Intern at Vasl Company"
excerpt: "Developed data pipelines and CDC systems with Apache NiFi; customized analytics dashboards using Apache Superset.<br/>"
collection: work
---

## ğŸ¢ About Vasl Company
**Vasl Company**, based in Tehran, provides software and data infrastructure solutions for enterprise clients.  
The company focuses on **data integration**, **streaming analytics**, and **monitoring platforms**, helping organizations transform raw data into actionable insights.

---

## ğŸ’¼ My Role
I worked as a **Data Engineer**, responsible for designing and maintaining **data pipelines**, **change data capture (CDC)** systems, and **data visualization tools** to unify and analyze data across multiple internal and external systems.

---

## ğŸš€ Key Achievements
- Built **scalable data pipelines** using **Apache NiFi** to integrate and manage data from multiple sources, including server logs and user activity streams.  
- Developed a **CDC (Change Data Capture)** mechanism across multiple **MongoDB clusters** and **ClickHouse** databases, ensuring real-time data consistency.  
- Designed and implemented **database integrations** connecting **ClickHouse** and **PostgreSQL** for analytics and reporting.  
- Customized **Apache Superset** dashboards, adding **Persian language support** and improving accessibility for local teams.

---

## ğŸ§° Technologies & Tools
**Apache NiFi**, **ClickHouse**, **PostgreSQL**, **ELK**, **MongoDB**, **Apache Superset**, **ETL Pipelines**, **CDC Systems**

---

## ğŸ’¡ Why It Matters to Me
This experience introduced me to the **world of data engineering** at scale, from pipeline orchestration to real-time analytics.  
It strengthened my understanding of **data flow design**, **ETL reliability**, and the **importance of data accessibility** in decision-making.  
It was also my first opportunity to work on **multi-database synchronization and dashboard customization** for production systems, which was both challenging and rewarding.
